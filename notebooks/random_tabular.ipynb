{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluating Rewards: Comparing Randomly Generated Tabular Reward Models",
      "version": "0.3.2",
      "provenance": [
        {
          "file_id": "1YBG5Bcycv9zk7-w1rQ8ThoMYyAhKyIYQ",
          "timestamp": 1566925978365
        }
      ],
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      }
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mWBbjXTm7Ixh"
      },
      "source": [
        "In this Colab, we perform a simple test of our reward model comparison technique on randomly generated reward models.\n",
        "\n",
        "This is the same idea as the notebook `random_deep.ipynb`, but in a tabular setting. This produces cleaner and quicker results, and is useful as a playground for rapidly testing out new ideas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_NBxahWcu8yg",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from evaluating_rewards import tabular\n",
        "from evaluating_rewards.experiments import util\n",
        "from evaluating_rewards.experiments import visualize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bzj6IGZHyy9_",
        "colab": {}
      },
      "source": [
        "# Global config\n",
        "n_states = 100\n",
        "n_actions = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wYEYCN9dDyIF",
        "colab": {}
      },
      "source": [
        "def run_shaping_comparison(reps=3, **kwargs):\n",
        "  dfs = []\n",
        "  # TODO(): seed to produce deterministically different results\n",
        "  for _ in range(reps):\n",
        "    with util.fresh_sess():\n",
        "      df = tabular.experiment_shaping_comparison(**kwargs)\n",
        "    dfs.append(df)\n",
        "  return dfs\n",
        "\n",
        "comparisons = run_shaping_comparison(n_states=n_states, n_actions=n_actions, state_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "czk8AY2bD-_C",
        "colab": {}
      },
      "source": [
        "def plot_shaping_comparison(dfs, **kwargs):\n",
        "  fig, axs = plt.subplots(1, len(dfs), figsize=(16, 4), squeeze=False)\n",
        "  longforms = []\n",
        "  for df, ax in zip(dfs, axs[0]):\n",
        "    longform = visualize.plot_shaping_comparison(df, ax=ax)\n",
        "    longforms.append(longform)\n",
        "  return longforms\n",
        "\n",
        "longform_comparisons = plot_shaping_comparison(comparisons)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GtpRsAV1ya1H",
        "colab": {}
      },
      "source": [
        "r1, p1, s1 = tabular.make_shaped_reward(n_states, n_actions, seed=0)\n",
        "r2, p2, s2 = tabular.make_shaped_reward(n_states, n_actions, seed=1)\n",
        "\n",
        "print('r1 vs s1', tabular.summary_comparison(r1, s1))\n",
        "print('s2 vs r1', tabular.summary_comparison(s2, r1))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
