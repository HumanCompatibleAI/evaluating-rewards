{
  "__doc__": "Sets dataset_factory_kwargs to defaults when dataset_factory not overridden.",
  "batch_size": 4096,
  "dataset_factory": {
    "py/function": "evaluating_rewards.datasets.rollout_serialized_policy_generator"
  },
  "dataset_factory_kwargs": {
    "policy_path": "dummy",
    "policy_type": "random"
  },
  "env_name": "evaluating_rewards/PointMassLine-v0",
  "learning_rate": 0.01,
  "log_dir": "PointMassLine-v0/evaluating_rewards_PointMassGroundTruth-v0_vs_evaluating_rewards_PointMassSparseWithCtrl-v0",
  "log_root": "/home/adam/output/model_comparison",
  "loss_fn": {
    "py/function": "tensorflow.python.ops.losses.losses_impl.mean_squared_error"
  },
  "model_reward_type": {
    "py/type": "evaluating_rewards.rewards.MLPRewardModel"
  },
  "model_wrapper_fn": {
    "py/function": "evaluating_rewards.comparisons.equivalence_model_wrapper"
  },
  "model_wrapper_kwargs": {},
  "pretrain": true,
  "pretrain_size": 16386,
  "seed": 0,
  "source_reward_path": "dummy",
  "source_reward_type": "evaluating_rewards/PointMassGroundTruth-v0",
  "target_reward_path": "dummy",
  "target_reward_type": "evaluating_rewards/PointMassSparseWithCtrl-v0",
  "total_timesteps": 8192
}